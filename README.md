# Awesome-Continual-Learning

## Prompt-based
### 2025
- <a name="todo"></a> Progressive Homeostatic and Plastic Prompt Tuning for Audio-Visual Multi-Task Incremental Learning (**ICCV 2025**) [[paper](https://arxiv.org/abs/2507.21588v1)][[code](https://github.com/ENJOY-Yin-jiong/PHP)]
- <a name="todo"></a> Achieving More with Less: Additive Prompt Tuning for Rehearsal-Free Class-Incremental Learning (**ICCV 2025**) [[paper](https://arxiv.org/pdf/2503.07979)][[code](https://github.com/HaoranChen/Additive-Prompt-Tuning)]
- <a name="todo"></a> RainbowPrompt: Diversity-Enhanced Prompt-Evolving for Continual Learning (**ICCV 2025**) [[paper](https://arxiv.org/abs/2507.22553)]
- <a name="todo"></a> PROL: Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning (**ICCV 2025**) [[paper](https://arxiv.org/abs/2507.12305)][[code](https://github.com/anwarmaxsum/PROL)]
- <a name="todo"></a> Hierarchical Visual Prompt Learning for Continual Video Instance Segmentation (**ICCV 2025**) [[paper](https://arxiv.org/pdf/2508.08612v1)][[code](https://github.com/JiahuaDong/HVPL)]
- <a name="todo"></a> Revisiting Pool-based Prompt Learning for Few-shot Class-incremental Learning (**ICCV 2025**) [[paper](https://arxiv.org/abs/2507.09183v2)][[code](https://github.com/Jywsuperman/LGSP)]
- <a name="todo"></a> Task-Aware Prompt Gradient Projection for Parameter-Efficient Tuning Federated Class-Incremental Learning (**ICCV 2025**) [[paper](https://openaccess.thecvf.com/content/ICCV2025/papers/Ke_Task-Aware_Prompt_Gradient_Projection_for_Parameter-Efficient_Tuning_Federated_Class-Incremental_Learning_ICCV_2025_paper.pdf)]
- <a name="todo"></a> Componential Prompt-Knowledge Alignment for Domain Incremental Learning (**ICML 2025**) [[paper](https://arxiv.org/pdf/2505.04575)][[code](https://github.com/zhoujiahuan1991/ICML2025-KA-Prompt)]
- <a name="todo"></a> iDPA: Instance Decoupled Prompt Attention for Incremental Medical Object Detection (**ICML 2025**) [[paper](https://arxiv.org/pdf/2506.00406)][[code](https://github.com/HarveyYi/iDPA)]
- <a name="todo"></a> Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation (**CVPR 2025**) [[paper](https://openaccess.thecvf.com//content/CVPR2025/papers/Yao_Think_Small_Act_Big_Primitive_Prompt_Learning_for_Lifelong_Robot_CVPR_2025_paper.pdf)]
- <a name="todo"></a> SEC-Prompt:SEmantic Complementary Prompting for Few-Shot Class-Incremental Learning (**CVPR 2025**) [[paper](https://openaccess.thecvf.com//content/CVPR2025/papers/Liu_SEC-PromptSEmantic_Complementary_Prompting_for_Few-Shot_Class-Incremental_Learning_CVPR_2025_paper.pdf)]
- <a name="todo"></a> Learning Conditional Space-Time Prompt Distributions for Video Class-Incremental Learning (**CVPR 2025**) [[paper](https://openaccess.thecvf.com/content/CVPR2025/papers/Zou_Learning_Conditional_Space-Time_Prompt_Distributions_for_Video_Class-Incremental_Learning_CVPR_2025_paper.pdf)][[code](https://github.com/Renovamen/CoSTEP)]
- <a name="todo"></a> Advancing Prompt-based Methods for Replay-Independent General Continual Learning (**ICLR 2025**) [[paper](https://openreview.net/forum?id=V6uxd8MEqw)][[code](https://github.com/kangzhiq/MISA)]
- <a name="todo"></a> Training Consistent Mixture-of-Experts-Based Prompt Generator for Continual Learning (**AAAI 2025**) [[paper](https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://ojs.aaai.org/index.php/AAAI/article/view/34108/36263&ved=2ahUKEwiD9YnX6reRAxUCVqQEHVdfFGIQFnoECBkQAQ&usg=AOvVaw3oQpOK1IBi0IoYaJZd4PbY)][[code](https://github.com/zugexiaodui/ConsistentMoEPromptGenerator)]
- <a name="todo"></a> Multiple Queries with Multiple Keys: A Precise Prompt Matching  Paradigm for Prompt-based Continual Learning (**ACM MM 2025**) [[paper](https://arxiv.org/abs/2501.12635)][[code](https://github.com/DunweiTu/MQMK)]

### 2024
- <a name="todo"></a> OVOR: OnePrompt with Virtual Outlier Regularization for Rehearsal-Free Class-Incremental Learning (**ICLR 2024**) [[paper](https://arxiv.org/abs/2402.04129)][[code](https://github.com/jpmorganchase/ovor)]
- <a name="todo"></a> Prompt Gradient Projection for Continual Learning (**ICLR2024**)[[paper](https://openreview.net/attachment?id=EH2O3h7sBI&name=pdf)][[code](https://github.com/JingyangQiao/prompt-gradient-projection)]
- <a name="todo"></a> Mixture of Experts Meets Prompt-Based Continual Learning (**NeurIPS 2024**) [[paper](https://arxiv.org/abs/2405.14124)][[code](https://github.com/Minhchuyentoancbn/MoE_PromptCL)]
- <a name="todo"></a> Vector Quantization Prompting for Continual Learning (**NeurIPS 2024**) [[paper](https://openreview.net/pdf/fe56049dfd050804f643de97820660c0ab7ace62.pdf)][[code](https://github.com/jiaolifengmi/VQ-Prompt)]
- <a name="todo"></a> Visual Prompt Tuning in Null Space for Continual Learning (**NeurIPS 2024**) [[paper](https://arxiv.org/abs/2406.05658)][[code](https://github.com/zugexiaodui/VPTinNSforCL)]
- <a name="todo"></a> Few-shot Class Incremental Learning with Attention-Aware Self-Adaptive Prompt (**ECCV24**)[[paper](https://arxiv.org/abs/2403.09857)][[code](https://github.com/DawnLIU35/FSCIL-ASP)]
- <a name="todo"></a> Semantic Residual Prompts for Continual Learning (**ECCV24**)[[paper](https://arxiv.org/abs/2403.06870)][[code](https://github.com/aimagelab/mammoth)]
- <a name="todo"></a> Beyond Prompt Learning: Continual Adapter for Efficient Rehearsal-Free Continual Learning (**ECCV24**)[[paper](https://arxiv.org/abs/2407.10281)]
- <a name="todo"></a> PromptFusion: Decoupling Stability and Plasticity for Continual Learning (**ECCV24**)[[paper](https://arxiv.org/abs/2303.07223)][[code](https://github.com/HaoranChen/PromptFusion)]
- <a name="todo"></a> One-stage Prompt-based Continual Learning (**ECCV24**)[[paper](https://arxiv.org/abs/2402.16189)]
- <a name="todo"></a> Open-World Dynamic Prompt and Continual Visual Representation Learning (**ECCV24**)[[paper](https://arxiv.org/abs/2409.05312)]
- <a name="todo"></a> PromptCCD: Learning Gaussian Mixture Prompt Pool for Continual Category Discovery (**ECCV24**)[[paper](https://arxiv.org/abs/2407.19001)][[code](https://visual-ai.github.io/promptccd)]
- <a name="todo"></a> RCS-Prompt: Learning Prompt to Rearrange Class Space for Prompt-based Continual Learning (**ECCV24**)[[paper](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/06307.pdf)][[code](https://github.com/longrongyang/RCS-Prompt)]
- <a name="todo"></a> Federated Continual Learning via Prompt-based Dual Knowledge Transfer (**ICML24**)[[paper](https://openreview.net/attachment?id=Kqa5JakTjB&name=pdf)][[code](https://github.com/piaohongming/Powder)]
- <a name="todo"></a> One Size Fits All for Semantic Shifts: Adaptive Prompt Tuning for Continual Learning (**ICML24**)[[paper](https://openreview.net/attachment?id=WUi1AqhKn5&name=pdf)]
- <a name="todo"></a> ECLIPSE: Efficient Continual Learning in Panoptic Segmentation with Visual Prompt Tuning (**CVPR2024**)[[paper](https://arxiv.org/abs/2403.20126)][[code](https://github.com/clovaai/ECLIPSE)]
- <a name="todo"></a> Consistent Prompting for Rehearsal-Free Continual Learning (**CVPR2024**)[[paper](https://arxiv.org/abs/2403.08568)][[code](https://github.com/Zhanxin-Gao/CPrompt)]
- <a name="todo"></a> Convolutional Prompting meets Language Models for Continual Learning (**CVPR2024**)[[paper](https://arxiv.org/pdf/2403.20317)][[code](https://github.com/CVIR/ConvPrompt)]
- <a name="todo"></a> Evolving Parameterized Prompt Memory for Continual Learning (**AAAI2024**)[[paper](https://ojs.aaai.org/index.php/AAAI/article/view/29231)][[code](https://github.com/MIV-XJTU/EvoPrompt)]
- <a name="todo"></a> Steering Prototypes with Prompt-tuning for Rehearsal-free Continual Learning (**WACV2024**)[[paper](https://arxiv.org/abs/2303.09447)][[code](https://github.com/LzVv123456/Contrastive-Prototypical-Prompt)]

### 2023
- <a name="todo"></a> Hierarchical Decomposition of Prompt-Based Continual Learning: Rethinking Obscured Sub-optimality (**NeurIPS 2023**)[[paper](https://arxiv.org/abs/2310.07234)]
- <a name="todo"></a> Self-regulating Prompts: Foundational Model Adaptation without Forgetting (**ICCV 2023**)[[paper](https://arxiv.org/abs/2307.06948)][[code](https://github.com/muzairkhattak/PromptSRC)]
- <a name="todo"></a> When Prompt-based Incremental Learning Does Not Meet Strong Pretraining (**ICCV 2023**)[[paper](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_When_Prompt-based_Incremental_Learning_Does_Not_Meet_Strong_Pretraining_ICCV_2023_paper.pdf)]
- <a name="todo"></a> Introducing Language Guidance in Prompt-based Continual Learning (**ICCV 2023**)[[paper](https://arxiv.org/abs/2308.15827)]
- <a name="todo"></a> PIVOT: Prompting for Video Continual Learning (**CVPR2023**)[[paper](https://arxiv.org/pdf/2212.04842.pdf)]
- <a name="todo"></a> CODA-Prompt: COntinual Decomposed Attention-based Prompting for Rehearsal-Free Continual Learning (**CVPR2023**)[[paper](https://arxiv.org/pdf/2211.13218.pdf)][[code](https://github.com/GT-RIPL/CODA-Prompt)]
- <a name="todo"></a> Progressive Prompts: Continual Learning for Language Models without Forgetting (**ICLR2023**)[[paper]( https://openreview.net/pdf?id=UJTgQBc91_)]

### 2022
- <a name="todo"></a> Incremental Prompting: Episodic Memory Prompt for Lifelong Event Detection (**COLING2022**) [[paper](https://arxiv.org/abs/2204.07275)] [[code]( https://github.com/VT-NLP/Incremental_Prompting)]
- <a name="todo"></a> S-Prompts Learning with Pre-trained Transformers: An Occamâ€™s Razor for Domain Incremental Learning (**NeurIPS2022**) [[paper](https://arxiv.org/abs/2207.12819)]
- <a name="todo"></a> DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning (**ECCV2022**) [[paper](https://arxiv.org/abs/2204.04799)] [[code](https://github.com/google-research/l2p)]
- <a name="todo"></a> Learning to Prompt for Continual Learning (**CVPR2022**) [[paper](https://arxiv.org/abs/2112.08654)] [[code](https://github.com/google-research/l2p)]

## Other pretrained-based
### 2024
- <a name="todo"></a> Revisiting Class-Incremental Learning with Pre-Trained Models: Generalizability and Adaptivity are All You Need (**IJCV 2024**) [[paper](https://arxiv.org/abs/2303.07338)][[code](https://github.com/LAMDA-CL/RevisitingCIL)]
